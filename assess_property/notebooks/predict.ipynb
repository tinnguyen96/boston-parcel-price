{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from assess_property.read_data import ReadAllYears\n",
    "from assess_property.preprocess import RemoveOutlier, ScaleTotalValue\n",
    "from assess_property.fit_learner import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and format csvs from disk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrs = range(2014,2024)\n",
    "vnames = [\"PID\", \"YR_REMODEL\", \"YR_BUILT\", \"LIVING_AREA\", \"LU\", \"ZIPCODE\", \"TOTAL_VALUE\",\"YEAR\"]\n",
    "reader = ReadAllYears(yrs, vnames)\n",
    "reader.read_all_years()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(reader.df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remover = RemoveOutlier(reader.df)\n",
    "remover.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change unit of total value\n",
    "\n",
    "Originally, total value is in dollars. We use units of hundred of thousands of dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ScaleTotalValue(remover.df)\n",
    "scaler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focus on R1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scaler.df[scaler.df[\"LU\"] == \"R1\"].copy()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validation experiment\n",
    "\n",
    "There is clear benefit to using light gbm over linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\"YR_BUILT\",\n",
    "             \"YEAR\",\n",
    "             \"YR_REMODEL\",\n",
    "            \"LIVING_AREA\"]\n",
    "response_name = \"TOTAL_VALUE_IN_HUNDRED_GRAND\"\n",
    "random_seed = 0\n",
    "n_fold = 10\n",
    "experiment = Experiment(df, \n",
    "                    var_names, \n",
    "                    response_name, \n",
    "                    n_fold=n_fold,\n",
    "                    random_seed = random_seed)\n",
    "experiment.set_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_cs_res = experiment.cv_fit(learner = \"lm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average absolute error is about $\\$270,000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_cs_res[\"test_neg_mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average absolute percentage error is about $50\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lm_cs_res[\"test_neg_mean_absolute_percentage_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_cs_res = experiment.cv_fit(learner = \"lgbm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average absolute error is about $\\$160,000$.\n",
    "There is clearly a benefit compared to using linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lgbm_cs_res[\"test_neg_mean_absolute_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average absolute percentage error is about $27\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lgbm_cs_res[\"test_neg_mean_absolute_percentage_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize errors as boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflist = []\n",
    "for prefix in [\"lm\", \"lgbm\"]:\n",
    "    name = \"%s_cs_res\" %prefix\n",
    "    d_ = locals()[name]\n",
    "    tempdf = pd.DataFrame.from_dict(d_)\n",
    "    tempdf[\"learner\"] = name\n",
    "    tempdf[\"fold_idx\"] = tempdf.index\n",
    "    dflist.append(tempdf)\n",
    "errdf = pd.concat(dflist).reset_index(drop=True)\n",
    "\n",
    "errdf = pd.wide_to_long(df = errdf,\n",
    "                stubnames=\"test\",\n",
    "                i = [\"learner\",\"fold_idx\"],\n",
    "                j = \"score_type\",\n",
    "                sep='_', \n",
    "                suffix=r'\\w+').reset_index()\n",
    "errdf.rename(columns = {\"test\": \"error\"}, inplace=True)\n",
    "errdf[\"error\"] = -errdf[\"error\"]\n",
    "errdf[\"error_type\"] = errdf[\"score_type\"].apply(lambda x: \"_\".join(x.split(\"_\")[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale = 1.0)\n",
    "g = sns.FacetGrid(data = errdf,\n",
    "                  height = 3,\n",
    "                  aspect =1.7,\n",
    "                  col=\"error_type\",\n",
    "                  sharex=False)\n",
    "\n",
    "g.map_dataframe(sns.boxplot,\n",
    "                x = \"error\",\n",
    "                y = \"learner\",\n",
    "                hue = \"learner\")\n",
    "g.add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One train-test split experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_names = [\"YR_BUILT\",\n",
    "             \"YEAR\",\n",
    "             \"YR_REMODEL\",\n",
    "            \"LIVING_AREA\"]\n",
    "response_name = \"TOTAL_VALUE_IN_HUNDRED_GRAND\"\n",
    "random_seed = 0\n",
    "n_fold = 10\n",
    "experiment = Experiment(df, \n",
    "                    var_names, \n",
    "                    response_name, \n",
    "                    n_fold=n_fold,\n",
    "                    random_seed = random_seed)\n",
    "experiment.set_up()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_vs_lgbm(fold_idx):\n",
    "    dflist = []\n",
    "    for name in [\"lm\", \"lgbm\"]: \n",
    "        _, ytest, _, ypred = experiment.fit(learner=name,\n",
    "                             fold_idx = 0)\n",
    "        epsilon = np.finfo(np.float64).eps\n",
    "        mape = np.abs(ypred - ytest) / np.maximum(np.abs(ytest), epsilon)\n",
    "        errdf = pd.DataFrame(data = mape[:,np.newaxis],\n",
    "                             columns= [\"error\"])\n",
    "        errdf[\"test_idx\"] = errdf.index\n",
    "        errdf[\"learner\"] = name \n",
    "        dflist.append(errdf)\n",
    "    errdf = pd.concat(dflist)\n",
    "    return errdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errdf = lm_vs_lgbm(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data = errdf,\n",
    "         log_scale = True,\n",
    "         x = \"error\",\n",
    "         hue = \"learner\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.boxplot(data = errdf,\n",
    "         x = \"error\",\n",
    "         y = \"learner\",\n",
    "         hue = \"learner\")\n",
    "g.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errdf.groupby(by = \"learner\")[\"error\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "no-pip-statistics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
